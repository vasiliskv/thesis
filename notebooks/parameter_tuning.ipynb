{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vasilis/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/weight_boosting.py:29: DeprecationWarning: numpy.core.umath_tests is an internal NumPy module and should not be imported. It will be removed in a future NumPy release.\n",
      "  from numpy.core.umath_tests import inner1d\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import Normalizer, MinMaxScaler, StandardScaler\n",
    "from sklearn.svm import SVC \n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# use seaborn plotting defaults\n",
    "import seaborn as sns; sns.set()\n",
    "\n",
    "\n",
    "features = pd.read_csv(\"../data/new_labeled_features.csv\",index_col=0)\n",
    "tfeatures = features.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(features.iloc[:,:-1], features.label, test_size=0.5, random_state=0)\n",
    "\n",
    "\n",
    "print('Grid Search for SVM')\n",
    "tuned_parameters = [{'kernel': ['rbf'], 'gamma': [1e-3, 1e-4], 'C': [1, 10, 100, 1000]}]\n",
    "clf = GridSearchCV(SVC(), tuned_parameters, cv=10)\n",
    "%time clf.fit(X_train, Y_train)\n",
    "#print(clf.best_params_)\n",
    "print()\n",
    "means = clf.cv_results_['mean_test_score']\n",
    "stds = clf.cv_results_['std_test_score']\n",
    "for mean, std, params in zip(means, stds, clf.cv_results_['params']):\n",
    "    print(\"%0.3f (+/-%0.03f) for %r\"% (mean, std * 2, params))\n",
    "print()\n",
    "print()\n",
    "y_true, y_pred = Y_test, clf.predict(X_test)\n",
    "print(classification_report(y_true, y_pred))\n",
    "\n",
    "\n",
    "print()\n",
    "print()\n",
    "print('Grid Search for kNN')\n",
    "tuned_parameters = [{'n_neighbors': [i for i in range(1,30)]}]\n",
    "clf = GridSearchCV(KNeighborsClassifier(), tuned_parameters, cv=10)\n",
    "%time clf.fit(X_train, Y_train)\n",
    "#print(clf.best_params_)\n",
    "print()\n",
    "means = clf.cv_results_['mean_test_score']\n",
    "stds = clf.cv_results_['std_test_score']\n",
    "for mean, std, params in zip(means, stds, clf.cv_results_['params']):\n",
    "    print(\"%0.3f (+/-%0.03f) for %r\"% (mean, std * 2, params))\n",
    "print()\n",
    "print()\n",
    "y_true, y_pred = Y_test, clf.predict(X_test)\n",
    "print(classification_report(y_true, y_pred))\n",
    "\n",
    "\n",
    "print()\n",
    "print()\n",
    "print('Grid Search for logistic regression')\n",
    "tuned_parameters = [{'C': [1,10,100,1000], 'tol': [1e-5,1e-4,1e-3]}]\n",
    "clf = GridSearchCV(LogisticRegression(), tuned_parameters, cv=10)\n",
    "%time clf.fit(X_train, Y_train)\n",
    "#print(clf.best_params_)\n",
    "print()\n",
    "means = clf.cv_results_['mean_test_score']\n",
    "stds = clf.cv_results_['std_test_score']\n",
    "for mean, std, params in zip(means, stds, clf.cv_results_['params']):\n",
    "    print(\"%0.3f (+/-%0.03f) for %r\"% (mean, std * 2, params))\n",
    "print()\n",
    "print()\n",
    "y_true, y_pred = Y_test, clf.predict(X_test)\n",
    "print(classification_report(y_true, y_pred))\n",
    "\n",
    "print()\n",
    "print()\n",
    "print('Grid Search for random forest')\n",
    "tuned_parameters = [{'n_estimators': [10, 50, 100, 150, 200]}]\n",
    "clf = GridSearchCV(RandomForestClassifier(), tuned_parameters, cv=10)\n",
    "%time clf.fit(X_train, Y_train)\n",
    "#print(clf.best_params_)\n",
    "print()\n",
    "means = clf.cv_results_['mean_test_score']\n",
    "stds = clf.cv_results_['std_test_score']\n",
    "for mean, std, params in zip(means, stds, clf.cv_results_['params']):\n",
    "    print(\"%0.3f (+/-%0.03f) for %r\"% (mean, std * 2, params))\n",
    "print()\n",
    "print()\n",
    "y_true, y_pred = Y_test, clf.predict(X_test)\n",
    "print(classification_report(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open(\"../reports/parameter_tuning\", 'a')\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(features.iloc[:,:-1], features.label, test_size=0.5, random_state=0)\n",
    "\n",
    "\n",
    "file.write('Grid Search for SVM\\n')\n",
    "tuned_parameters = [{'kernel': ['rbf'], 'gamma': [1e-3, 1e-4], 'C': [1, 10, 100, 1000]}]\n",
    "clf = GridSearchCV(SVC(), tuned_parameters, cv=10)\n",
    "%time clf.fit(X_train, Y_train)\n",
    "#print(clf.best_params_)\n",
    "file.write('\\n')\n",
    "means = clf.cv_results_['mean_test_score']\n",
    "stds = clf.cv_results_['std_test_score']\n",
    "for mean, std, params in zip(means, stds, clf.cv_results_['params']):\n",
    "    file.write(\"%0.3f (+/-%0.03f) for %r\\n\"% (mean, std * 2, params))\n",
    "file.write('\\n')\n",
    "file.write('\\n')\n",
    "y_true, y_pred = Y_test, clf.predict(X_test)\n",
    "file.write(classification_report(y_true, y_pred))\n",
    "\n",
    "file.write('\\n')\n",
    "file.write('\\n')\n",
    "file.write('\\n')\n",
    "file.write('Grid Search for kNN\\n')\n",
    "tuned_parameters = [{'n_neighbors': [i for i in range(1,30)]}]\n",
    "clf = GridSearchCV(KNeighborsClassifier(), tuned_parameters, cv=10)\n",
    "%time clf.fit(X_train, Y_train)\n",
    "#print(clf.best_params_)\n",
    "file.write('\\n')\n",
    "means = clf.cv_results_['mean_test_score']\n",
    "stds = clf.cv_results_['std_test_score']\n",
    "for mean, std, params in zip(means, stds, clf.cv_results_['params']):\n",
    "    file.write(\"%0.3f (+/-%0.03f) for %r\\n\"% (mean, std * 2, params))\n",
    "file.write('\\n')\n",
    "file.write('\\n')\n",
    "y_true, y_pred = Y_test, clf.predict(X_test)\n",
    "file.write(classification_report(y_true, y_pred))\n",
    "\n",
    "file.write('\\n')\n",
    "file.write('\\n')\n",
    "file.write('\\n')\n",
    "file.write('Grid Search for logistic regression\\n')\n",
    "tuned_parameters = [{'C': [1,10,100,1000], 'tol': [1e-5,1e-4,1e-3]}]\n",
    "clf = GridSearchCV(LogisticRegression(), tuned_parameters, cv=10)\n",
    "%time clf.fit(X_train, Y_train)\n",
    "#print(clf.best_params_)\n",
    "file.write('\\n')\n",
    "means = clf.cv_results_['mean_test_score']\n",
    "stds = clf.cv_results_['std_test_score']\n",
    "for mean, std, params in zip(means, stds, clf.cv_results_['params']):\n",
    "    file.write(\"%0.3f (+/-%0.03f) for %r\\n\"% (mean, std * 2, params))\n",
    "file.write('\\n')\n",
    "file.write('\\n')\n",
    "y_true, y_pred = Y_test, clf.predict(X_test)\n",
    "file.writelines(classification_report(y_true, y_pred))\n",
    "\n",
    "file.write('\\n')\n",
    "file.write('\\n')\n",
    "file.write('\\n')\n",
    "file.write('Grid Search for random forest\\n')\n",
    "tuned_parameters = [{'n_estimators': [10, 50, 100, 150, 200]}]\n",
    "clf = GridSearchCV(RandomForestClassifier(), tuned_parameters, cv=10)\n",
    "%time clf.fit(X_train, Y_train)\n",
    "#print(clf.best_params_)\n",
    "file.write('\\n')\n",
    "means = clf.cv_results_['mean_test_score']\n",
    "stds = clf.cv_results_['std_test_score']\n",
    "for mean, std, params in zip(means, stds, clf.cv_results_['params']):\n",
    "    file.write(\"%0.3f (+/-%0.03f) for %r\\n\"% (mean, std * 2, params))\n",
    "file.write('\\n')\n",
    "file.write('\\n')\n",
    "y_true, y_pred = Y_test, clf.predict(X_test)\n",
    "file.writelines(classification_report(y_true, y_pred))\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 38.9 s, sys: 4 ms, total: 38.9 s\n",
      "Wall time: 38.9 s\n",
      "CPU times: user 1min 24s, sys: 1.12 s, total: 1min 25s\n",
      "Wall time: 48.8 s\n",
      "CPU times: user 45.5 s, sys: 916 ms, total: 46.4 s\n",
      "Wall time: 27.5 s\n",
      "CPU times: user 58.9 s, sys: 20 ms, total: 58.9 s\n",
      "Wall time: 58.8 s\n"
     ]
    }
   ],
   "source": [
    "file = open(\"../reports/parameter_tuning\", 'w')\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(features.iloc[:,:-1], features.label, test_size=0.5, random_state=0)\n",
    "\n",
    "estimators_list = [SVC(),KNeighborsClassifier(), LogisticRegression(), RandomForestClassifier()]\n",
    "tuned_parameters_list = [[{'kernel': ['rbf'], 'gamma': [1e-3, 1e-4], 'C': [1, 10, 100, 1000]}],\n",
    "                         [{'n_neighbors': [i for i in range(1,30)]}], \n",
    "                         [{'C': [1,10,100,1000], 'tol': [1e-5,1e-4,1e-3]}], \n",
    "                         [{'n_estimators': [10, 50, 100, 150, 200]}]]\n",
    "names_list = [\"SVM\", \"KNN\", \"LR\", \"RF\"]\n",
    "\n",
    "for estimator, tuned_parameters, name in zip(estimators_list, tuned_parameters_list, names_list):\n",
    "    file.write(30*\"**\"+\"\\n\")\n",
    "    file.write('Grid Search for '+ name +'\\n')\n",
    "    clf = GridSearchCV(estimator, tuned_parameters, cv=10)\n",
    "    %time clf.fit(X_train, Y_train)\n",
    "    file.write(str(clf.best_params_))\n",
    "    file.write('\\n')\n",
    "    means = clf.cv_results_['mean_test_score']\n",
    "    stds = clf.cv_results_['std_test_score']\n",
    "    for mean, std, params in zip(means, stds, clf.cv_results_['params']):\n",
    "        file.write(\"%0.3f (+/-%0.03f) for %r\\n\"% (mean, std * 2, params))\n",
    "    file.write('\\nmean accuracy score:'+str(means.sum()/len(means)))\n",
    "    file.write('\\n')\n",
    "    file.write('\\n')\n",
    "    y_true, y_pred = Y_test, clf.predict(X_test)\n",
    "    file.write(classification_report(y_true, y_pred))\n",
    "    file.write('\\n')\n",
    "    file.write('\\n')\n",
    "    file.write('\\n')\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 33.9 s, sys: 20 ms, total: 33.9 s\n",
      "Wall time: 33.8 s\n",
      "CPU times: user 2min 55s, sys: 1.29 s, total: 2min 56s\n",
      "Wall time: 2min 16s\n",
      "CPU times: user 16.9 s, sys: 352 ms, total: 17.3 s\n",
      "Wall time: 8.84 s\n",
      "CPU times: user 1min 5s, sys: 16 ms, total: 1min 5s\n",
      "Wall time: 1min 5s\n",
      "\n",
      "\n",
      "\n",
      "CPU times: user 34.3 s, sys: 12 ms, total: 34.3 s\n",
      "Wall time: 34.2 s\n",
      "CPU times: user 2min 47s, sys: 1.29 s, total: 2min 48s\n",
      "Wall time: 2min 8s\n",
      "CPU times: user 1min 41s, sys: 808 ms, total: 1min 42s\n",
      "Wall time: 1min 20s\n",
      "CPU times: user 1min 8s, sys: 12 ms, total: 1min 8s\n",
      "Wall time: 1min 8s\n",
      "\n",
      "\n",
      "\n",
      "CPU times: user 33.4 s, sys: 0 ns, total: 33.4 s\n",
      "Wall time: 33.3 s\n",
      "CPU times: user 1min 49s, sys: 1.22 s, total: 1min 51s\n",
      "Wall time: 1min 10s\n",
      "CPU times: user 25.6 s, sys: 492 ms, total: 26.1 s\n",
      "Wall time: 13.7 s\n",
      "CPU times: user 1min 4s, sys: 8 ms, total: 1min 4s\n",
      "Wall time: 1min 4s\n"
     ]
    }
   ],
   "source": [
    "#construction of the lists\n",
    "estimators_list = [SVC(),KNeighborsClassifier(), LogisticRegression(), RandomForestClassifier()]\n",
    "tuned_parameters_list = [[{'kernel': ['rbf'], 'gamma': [1e-3, 1e-4], 'C': [1, 10, 100, 1000]}],\n",
    "                         [{'n_neighbors': [i for i in range(1,30)]}], \n",
    "                         [{'C': [1,10,100,1000], 'tol': [1e-5,1e-4,1e-3]}], \n",
    "                         [{'n_estimators': [10, 50, 100, 150, 200]}]]\n",
    "norm_list = [Normalizer(), StandardScaler(), MinMaxScaler()]\n",
    "names_list = [\"SVM\", \"KNN\", \"LR\", \"RF\"]\n",
    "transforms_list = [\"norm\",\"scale\",\"minmax\"]\n",
    "\n",
    "\n",
    "#breaking the data\n",
    "labels = features.label\n",
    "\n",
    "#normalization of the data\n",
    "tnfeatures = norm_list[0].transform(tfeatures.iloc[:-1,:])\n",
    "nfeatures = tnfeatures.T\n",
    "pfeatures = pd.concat([pd.DataFrame(data=nfeatures), labels], axis=1)\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(pfeatures.iloc[:, :-1], pfeatures['label'], test_size=0.5, random_state=0)\n",
    "file = open(\"../reports/parameter_tuning_\"+transforms_list[0], 'w')\n",
    "\n",
    "for estimator, tuned_parameters, name in zip(estimators_list, tuned_parameters_list, names_list):\n",
    "    file.write(30*\"**\"+\"\\n\")\n",
    "    file.write('Grid Search for '+ name +'\\n')\n",
    "    clf = GridSearchCV(estimator, tuned_parameters, cv=10)\n",
    "    %time clf.fit(X_train, Y_train)\n",
    "    file.write(str(clf.best_params_))\n",
    "    file.write(str(clf.best_estimator_))\n",
    "    file.write('\\n')\n",
    "    means = clf.cv_results_['mean_test_score']\n",
    "    stds = clf.cv_results_['std_test_score']\n",
    "    for mean, std, params in zip(means, stds, clf.cv_results_['params']):\n",
    "        file.write(\"%0.3f (+/-%0.03f) for %r\\n\"% (mean, std * 2, params))\n",
    "    file.write('\\nmean accuracy score:'+str(means.sum()/len(means)))\n",
    "    file.write('\\n')\n",
    "    file.write('\\n')\n",
    "    y_true, y_pred = Y_test, clf.predict(X_test)\n",
    "    file.write(classification_report(y_true, y_pred))\n",
    "    file.write('\\n')\n",
    "    file.write('\\n')\n",
    "    file.write('\\n')\n",
    "file.close()\n",
    "\n",
    "#scaling of the data\n",
    "for norm, trans in zip(norm_list[1:], transforms_list[1:]):\n",
    "    print()\n",
    "    print()\n",
    "    print()\n",
    "    nfeatures = norm.fit_transform(features.iloc[:, :-1])\n",
    "    ###############################################################\n",
    "    pfeatures = pd.concat([pd.DataFrame(data=nfeatures), labels], axis=1)\n",
    "    ###############################################################\n",
    "    X_train, X_test, Y_train, Y_test = train_test_split(pfeatures.iloc[:, :-1], pfeatures['label'], test_size=0.5, random_state=0)\n",
    "    file = open(\"../reports/parameter_tuning_\"+trans, 'w')\n",
    "\n",
    "    for estimator, tuned_parameters, name in zip(estimators_list, tuned_parameters_list, names_list):\n",
    "        file.write(30*\"**\"+\"\\n\")\n",
    "        file.write('Grid Search for '+ name +'\\n')\n",
    "        clf = GridSearchCV(estimator, tuned_parameters, cv=10)\n",
    "        %time clf.fit(X_train, Y_train)\n",
    "        file.write(str(clf.best_params_))\n",
    "        file.write(str(clf.best_estimator_))\n",
    "        file.write('\\n')\n",
    "        means = clf.cv_results_['mean_test_score']\n",
    "        stds = clf.cv_results_['std_test_score']\n",
    "        for mean, std, params in zip(means, stds, clf.cv_results_['params']):\n",
    "            file.write(\"%0.3f (+/-%0.03f) for %r\\n\"% (mean, std * 2, params))\n",
    "        file.write('\\nmean accuracy score:'+str(means.sum()/len(means)))\n",
    "        file.write('\\n')\n",
    "        file.write('\\n')\n",
    "        y_true, y_pred = Y_test, clf.predict(X_test)\n",
    "        file.write(classification_report(y_true, y_pred))\n",
    "        file.write('\\n')\n",
    "        file.write('\\n')\n",
    "        file.write('\\n')\n",
    "    file.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 33.9 s, sys: 44 ms, total: 33.9 s\n",
      "Wall time: 33.9 s\n",
      "CPU times: user 2min 44s, sys: 1.28 s, total: 2min 46s\n",
      "Wall time: 2min 4s\n",
      "CPU times: user 16.1 s, sys: 408 ms, total: 16.5 s\n",
      "Wall time: 8.28 s\n",
      "CPU times: user 1min, sys: 8 ms, total: 1min\n",
      "Wall time: 1min\n",
      "\n",
      "\n",
      "\n",
      "CPU times: user 31.3 s, sys: 0 ns, total: 31.3 s\n",
      "Wall time: 31.1 s\n",
      "CPU times: user 3min 41s, sys: 1.36 s, total: 3min 43s\n",
      "Wall time: 3min 2s\n",
      "CPU times: user 1min 41s, sys: 956 ms, total: 1min 42s\n",
      "Wall time: 1min 20s\n",
      "CPU times: user 1min 8s, sys: 36 ms, total: 1min 9s\n",
      "Wall time: 1min 8s\n",
      "\n",
      "\n",
      "\n",
      "CPU times: user 32 s, sys: 8 ms, total: 32 s\n",
      "Wall time: 31.8 s\n",
      "CPU times: user 1min 47s, sys: 1.13 s, total: 1min 48s\n",
      "Wall time: 1min 6s\n",
      "CPU times: user 25.7 s, sys: 504 ms, total: 26.2 s\n",
      "Wall time: 13.6 s\n",
      "CPU times: user 1min 2s, sys: 84 ms, total: 1min 2s\n",
      "Wall time: 1min 2s\n"
     ]
    }
   ],
   "source": [
    "#construction of the lists\n",
    "estimators_list = [SVC(),KNeighborsClassifier(), LogisticRegression(), RandomForestClassifier()]\n",
    "tuned_parameters_list = [[{'kernel': ['rbf'], 'gamma': [1e-3, 1e-4], 'C': [1, 10, 100, 1000]}],\n",
    "                         [{'n_neighbors': [i for i in range(1,30)]}], \n",
    "                         [{'C': [1,10,100,1000], 'tol': [1e-5,1e-4,1e-3]}], \n",
    "                         [{'n_estimators': [10, 50, 100, 150, 200]}]]\n",
    "norm_list = [Normalizer(), StandardScaler(), MinMaxScaler()]\n",
    "names_list = [\"SVM\", \"KNN\", \"LR\", \"RF\"]\n",
    "transforms_list = [\"norm\",\"scale\",\"minmax\"]\n",
    "\n",
    "\n",
    "#breaking the data\n",
    "labels = features.label\n",
    "\n",
    "#normalization of the data\n",
    "tnfeatures = norm_list[0].transform(tfeatures.iloc[:-1,:])\n",
    "nfeatures = tnfeatures.T\n",
    "pfeatures = pd.concat([pd.DataFrame(data=nfeatures), labels], axis=1)\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(pfeatures.iloc[:, :-1], pfeatures['label'], test_size=0.5, random_state=0)\n",
    "file = open(\"../reports/nparameter_tuning_\"+transforms_list[0], 'w')\n",
    "\n",
    "for estimator, tuned_parameters, name in zip(estimators_list, tuned_parameters_list, names_list):\n",
    "    file.write(30*\"**\"+\"\\n\")\n",
    "    file.write('Grid Search for '+ name +'\\n')\n",
    "    clf = GridSearchCV(estimator, tuned_parameters, cv=10, scoring='roc_auc')\n",
    "    %time clf.fit(X_train, Y_train)\n",
    "    file.write(str(clf.best_params_))\n",
    "    file.write('\\n')\n",
    "    means = clf.cv_results_['mean_test_score']\n",
    "    stds = clf.cv_results_['std_test_score']\n",
    "    for mean, std, params in zip(means, stds, clf.cv_results_['params']):\n",
    "        file.write(\"%0.3f (+/-%0.03f) for %r\\n\"% (mean, std * 2, params))\n",
    "    file.write('\\n')\n",
    "    file.write('\\n')\n",
    "    y_true, y_pred = Y_test, clf.predict(X_test)\n",
    "    file.write(classification_report(y_true, y_pred))\n",
    "    file.write('\\n')\n",
    "    file.write('\\n')\n",
    "    file.write('\\n')\n",
    "file.close()\n",
    "\n",
    "#scaling of the data\n",
    "for norm, trans in zip(norm_list[1:], transforms_list[1:]):\n",
    "    print()\n",
    "    print()\n",
    "    print()\n",
    "    nfeatures = norm.fit_transform(features.iloc[:, :-1])\n",
    "    ###############################################################\n",
    "    pfeatures = pd.concat([pd.DataFrame(data=nfeatures), labels], axis=1)\n",
    "    ###############################################################\n",
    "    X_train, X_test, Y_train, Y_test = train_test_split(pfeatures.iloc[:, :-1], pfeatures['label'], test_size=0.5, random_state=0)\n",
    "    file = open(\"../reports/nparameter_tuning_\"+trans, 'w')\n",
    "\n",
    "    for estimator, tuned_parameters, name in zip(estimators_list, tuned_parameters_list, names_list):\n",
    "        file.write(30*\"**\"+\"\\n\")\n",
    "        file.write('Grid Search for '+ name +'\\n')\n",
    "        clf = GridSearchCV(estimator, tuned_parameters, cv=10, scoring='roc_auc')\n",
    "        %time clf.fit(X_train, Y_train)\n",
    "        file.write(str(clf.best_params_))\n",
    "        file.write('\\n')\n",
    "        means = clf.cv_results_['mean_test_score']\n",
    "        stds = clf.cv_results_['std_test_score']\n",
    "        for mean, std, params in zip(means, stds, clf.cv_results_['params']):\n",
    "            file.write(\"%0.3f (+/-%0.03f) for %r\\n\"% (mean, std * 2, params))\n",
    "        file.write('\\n')\n",
    "        file.write('\\n')\n",
    "        y_true, y_pred = Y_test, clf.predict(X_test)\n",
    "        file.write(classification_report(y_true, y_pred))\n",
    "        file.write('\\n')\n",
    "        file.write('\\n')\n",
    "        file.write('\\n')\n",
    "    file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimators_list = [SVC(),KNeighborsClassifier(), LogisticRegression(), RandomForestClassifier()]\n",
    "tuned_parameters_list = [[{'kernel': ['rbf'], 'gamma': [1e-3, 1e-4], 'C': [1, 10, 100, 1000]}],\n",
    "                         [{'n_neighbors': [i for i in range(1,30)]}], \n",
    "                         [{'C': [1,10,100,1000], 'tol': [1e-5,1e-4,1e-3]}], \n",
    "                         [{'n_estimators': [10, 50, 100, 150, 200]}]]\n",
    "norm_list = [Normalizer(), StandardScaler(), MinMaxScaler()]\n",
    "names_list = [\"SVM\", \"KNN\", \"LR\", \"RF\"]\n",
    "transforms_list = [\"norm\",\"scale\",\"minmax\"]\n",
    "\n",
    "tnfeatures = norm_list[0].transform(tfeatures)\n",
    "nfeatures = tnfeatures.T\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(nfeatures[:,:-1], nfeatures[:, -1], test_size=0.5, random_state=0)\n",
    "for estimator, tuned_parameters, name in zip(estimators_list, tuned_parameters_list, names_list):\n",
    "    print(estimator)\n",
    "    print(tuned_parameters)\n",
    "    print(name)\n",
    "    print()\n",
    "    print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
