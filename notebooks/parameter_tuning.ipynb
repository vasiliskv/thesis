{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(113,)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import Normalizer, MinMaxScaler, StandardScaler\n",
    "from sklearn.svm import SVC \n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# use seaborn plotting defaults\n",
    "import seaborn as sns; sns.set()\n",
    "\n",
    "\n",
    "features = pd.read_csv(\"../data/new_labeled_features.csv\",index_col=0)\n",
    "tfeatures = features.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(features.iloc[:,:-1], features.label, test_size=0.5, random_state=0)\n",
    "\n",
    "\n",
    "print('Grid Search for SVM')\n",
    "tuned_parameters = [{'kernel': ['rbf'], 'gamma': [1e-3, 1e-4], 'C': [1, 10, 100, 1000]}]\n",
    "clf = GridSearchCV(SVC(), tuned_parameters, cv=10)\n",
    "%time clf.fit(X_train, Y_train)\n",
    "#print(clf.best_params_)\n",
    "print()\n",
    "means = clf.cv_results_['mean_test_score']\n",
    "stds = clf.cv_results_['std_test_score']\n",
    "for mean, std, params in zip(means, stds, clf.cv_results_['params']):\n",
    "    print(\"%0.3f (+/-%0.03f) for %r\"% (mean, std * 2, params))\n",
    "print()\n",
    "print()\n",
    "y_true, y_pred = Y_test, clf.predict(X_test)\n",
    "print(classification_report(y_true, y_pred))\n",
    "\n",
    "\n",
    "print()\n",
    "print()\n",
    "print('Grid Search for kNN')\n",
    "tuned_parameters = [{'n_neighbors': [i for i in range(1,30)]}]\n",
    "clf = GridSearchCV(KNeighborsClassifier(), tuned_parameters, cv=10)\n",
    "%time clf.fit(X_train, Y_train)\n",
    "#print(clf.best_params_)\n",
    "print()\n",
    "means = clf.cv_results_['mean_test_score']\n",
    "stds = clf.cv_results_['std_test_score']\n",
    "for mean, std, params in zip(means, stds, clf.cv_results_['params']):\n",
    "    print(\"%0.3f (+/-%0.03f) for %r\"% (mean, std * 2, params))\n",
    "print()\n",
    "print()\n",
    "y_true, y_pred = Y_test, clf.predict(X_test)\n",
    "print(classification_report(y_true, y_pred))\n",
    "\n",
    "\n",
    "print()\n",
    "print()\n",
    "print('Grid Search for logistic regression')\n",
    "tuned_parameters = [{'C': [1,10,100,1000], 'tol': [1e-5,1e-4,1e-3]}]\n",
    "clf = GridSearchCV(LogisticRegression(), tuned_parameters, cv=10)\n",
    "%time clf.fit(X_train, Y_train)\n",
    "#print(clf.best_params_)\n",
    "print()\n",
    "means = clf.cv_results_['mean_test_score']\n",
    "stds = clf.cv_results_['std_test_score']\n",
    "for mean, std, params in zip(means, stds, clf.cv_results_['params']):\n",
    "    print(\"%0.3f (+/-%0.03f) for %r\"% (mean, std * 2, params))\n",
    "print()\n",
    "print()\n",
    "y_true, y_pred = Y_test, clf.predict(X_test)\n",
    "print(classification_report(y_true, y_pred))\n",
    "\n",
    "print()\n",
    "print()\n",
    "print('Grid Search for random forest')\n",
    "tuned_parameters = [{'n_estimators': [10, 50, 100, 150, 200]}]\n",
    "clf = GridSearchCV(RandomForestClassifier(), tuned_parameters, cv=10)\n",
    "%time clf.fit(X_train, Y_train)\n",
    "#print(clf.best_params_)\n",
    "print()\n",
    "means = clf.cv_results_['mean_test_score']\n",
    "stds = clf.cv_results_['std_test_score']\n",
    "for mean, std, params in zip(means, stds, clf.cv_results_['params']):\n",
    "    print(\"%0.3f (+/-%0.03f) for %r\"% (mean, std * 2, params))\n",
    "print()\n",
    "print()\n",
    "y_true, y_pred = Y_test, clf.predict(X_test)\n",
    "print(classification_report(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open(\"../reports/parameter_tuning\", 'a')\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(features.iloc[:,:-1], features.label, test_size=0.5, random_state=0)\n",
    "\n",
    "\n",
    "file.write('Grid Search for SVM\\n')\n",
    "tuned_parameters = [{'kernel': ['rbf'], 'gamma': [1e-3, 1e-4], 'C': [1, 10, 100, 1000]}]\n",
    "clf = GridSearchCV(SVC(), tuned_parameters, cv=10)\n",
    "%time clf.fit(X_train, Y_train)\n",
    "#print(clf.best_params_)\n",
    "file.write('\\n')\n",
    "means = clf.cv_results_['mean_test_score']\n",
    "stds = clf.cv_results_['std_test_score']\n",
    "for mean, std, params in zip(means, stds, clf.cv_results_['params']):\n",
    "    file.write(\"%0.3f (+/-%0.03f) for %r\\n\"% (mean, std * 2, params))\n",
    "file.write('\\n')\n",
    "file.write('\\n')\n",
    "y_true, y_pred = Y_test, clf.predict(X_test)\n",
    "file.write(classification_report(y_true, y_pred))\n",
    "\n",
    "file.write('\\n')\n",
    "file.write('\\n')\n",
    "file.write('\\n')\n",
    "file.write('Grid Search for kNN\\n')\n",
    "tuned_parameters = [{'n_neighbors': [i for i in range(1,30)]}]\n",
    "clf = GridSearchCV(KNeighborsClassifier(), tuned_parameters, cv=10)\n",
    "%time clf.fit(X_train, Y_train)\n",
    "#print(clf.best_params_)\n",
    "file.write('\\n')\n",
    "means = clf.cv_results_['mean_test_score']\n",
    "stds = clf.cv_results_['std_test_score']\n",
    "for mean, std, params in zip(means, stds, clf.cv_results_['params']):\n",
    "    file.write(\"%0.3f (+/-%0.03f) for %r\\n\"% (mean, std * 2, params))\n",
    "file.write('\\n')\n",
    "file.write('\\n')\n",
    "y_true, y_pred = Y_test, clf.predict(X_test)\n",
    "file.write(classification_report(y_true, y_pred))\n",
    "\n",
    "file.write('\\n')\n",
    "file.write('\\n')\n",
    "file.write('\\n')\n",
    "file.write('Grid Search for logistic regression\\n')\n",
    "tuned_parameters = [{'C': [1,10,100,1000], 'tol': [1e-5,1e-4,1e-3]}]\n",
    "clf = GridSearchCV(LogisticRegression(), tuned_parameters, cv=10)\n",
    "%time clf.fit(X_train, Y_train)\n",
    "#print(clf.best_params_)\n",
    "file.write('\\n')\n",
    "means = clf.cv_results_['mean_test_score']\n",
    "stds = clf.cv_results_['std_test_score']\n",
    "for mean, std, params in zip(means, stds, clf.cv_results_['params']):\n",
    "    file.write(\"%0.3f (+/-%0.03f) for %r\\n\"% (mean, std * 2, params))\n",
    "file.write('\\n')\n",
    "file.write('\\n')\n",
    "y_true, y_pred = Y_test, clf.predict(X_test)\n",
    "file.writelines(classification_report(y_true, y_pred))\n",
    "\n",
    "file.write('\\n')\n",
    "file.write('\\n')\n",
    "file.write('\\n')\n",
    "file.write('Grid Search for random forest\\n')\n",
    "tuned_parameters = [{'n_estimators': [10, 50, 100, 150, 200]}]\n",
    "clf = GridSearchCV(RandomForestClassifier(), tuned_parameters, cv=10)\n",
    "%time clf.fit(X_train, Y_train)\n",
    "#print(clf.best_params_)\n",
    "file.write('\\n')\n",
    "means = clf.cv_results_['mean_test_score']\n",
    "stds = clf.cv_results_['std_test_score']\n",
    "for mean, std, params in zip(means, stds, clf.cv_results_['params']):\n",
    "    file.write(\"%0.3f (+/-%0.03f) for %r\\n\"% (mean, std * 2, params))\n",
    "file.write('\\n')\n",
    "file.write('\\n')\n",
    "y_true, y_pred = Y_test, clf.predict(X_test)\n",
    "file.writelines(classification_report(y_true, y_pred))\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open(\"../reports/parameter_tuning\", 'w')\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(features.iloc[:,:-1], features.label, test_size=0.5, random_state=0)\n",
    "\n",
    "estimators_list = [SVC(),KNeighborsClassifier(), LogisticRegression(), RandomForestClassifier()]\n",
    "tuned_parameters_list = [[{'kernel': ['rbf'], 'gamma': [1e-3, 1e-4], 'C': [1, 10, 100, 1000]}],\n",
    "                         [{'n_neighbors': [i for i in range(1,30)]}], \n",
    "                         [{'C': [1,10,100,1000], 'tol': [1e-5,1e-4,1e-3]}], \n",
    "                         [{'n_estimators': [10, 50, 100, 150, 200]}]]\n",
    "names_list = [\"SVM\", \"KNN\", \"LR\", \"RF\"]\n",
    "\n",
    "for estimator, tuned_parameters, name in zip(estimators_list, tuned_parameters_list, names_list):\n",
    "    file.write(30*\"**\"+\"\\n\")\n",
    "    file.write('Grid Search for '+ name +'\\n')\n",
    "    clf = GridSearchCV(estimator, tuned_parameters, cv=10)\n",
    "    %time clf.fit(X_train, Y_train)\n",
    "    print(clf.best_params_)\n",
    "    file.write('\\n')\n",
    "    means = clf.cv_results_['mean_test_score']\n",
    "    stds = clf.cv_results_['std_test_score']\n",
    "    for mean, std, params in zip(means, stds, clf.cv_results_['params']):\n",
    "        file.write(\"%0.3f (+/-%0.03f) for %r\\n\"% (mean, std * 2, params))\n",
    "    file.write('\\n')\n",
    "    file.write('\\n')\n",
    "    y_true, y_pred = Y_test, clf.predict(X_test)\n",
    "    file.write(classification_report(y_true, y_pred))\n",
    "    file.write('\\n')\n",
    "    file.write('\\n')\n",
    "    file.write('\\n')\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0        True\n",
      "1        True\n",
      "2        True\n",
      "3        True\n",
      "4       False\n",
      "5        True\n",
      "6       False\n",
      "7       False\n",
      "8       False\n",
      "9       False\n",
      "10      False\n",
      "11      False\n",
      "12      False\n",
      "13      False\n",
      "14       True\n",
      "15       True\n",
      "16      False\n",
      "17      False\n",
      "18      False\n",
      "19      False\n",
      "20       True\n",
      "21      False\n",
      "22      False\n",
      "23      False\n",
      "24      False\n",
      "25      False\n",
      "26      False\n",
      "27      False\n",
      "28      False\n",
      "29      False\n",
      "        ...  \n",
      "4116    False\n",
      "4117    False\n",
      "4118    False\n",
      "4119    False\n",
      "4120    False\n",
      "4121    False\n",
      "4122    False\n",
      "4123    False\n",
      "4124    False\n",
      "4125    False\n",
      "4126    False\n",
      "4127    False\n",
      "4128    False\n",
      "4129    False\n",
      "4130    False\n",
      "4131    False\n",
      "4132    False\n",
      "4133    False\n",
      "4134    False\n",
      "4135    False\n",
      "4136    False\n",
      "4137    False\n",
      "4138    False\n",
      "4139    False\n",
      "4140    False\n",
      "4141    False\n",
      "4142    False\n",
      "4143    False\n",
      "4144    False\n",
      "4145     True\n",
      "Name: label, Length: 4146, dtype: bool\n",
      "CPU times: user 31.2 s, sys: 0 ns, total: 31.2 s\n",
      "Wall time: 31 s\n",
      "CPU times: user 2min 35s, sys: 1.08 s, total: 2min 36s\n",
      "Wall time: 1min 54s\n",
      "CPU times: user 14.3 s, sys: 320 ms, total: 14.7 s\n",
      "Wall time: 7.42 s\n",
      "CPU times: user 1min, sys: 8 ms, total: 1min\n",
      "Wall time: 1min\n",
      "\n",
      "\n",
      "\n",
      "0        True\n",
      "1        True\n",
      "2        True\n",
      "3        True\n",
      "4       False\n",
      "5        True\n",
      "6       False\n",
      "7       False\n",
      "8       False\n",
      "9       False\n",
      "10      False\n",
      "11      False\n",
      "12      False\n",
      "13      False\n",
      "14       True\n",
      "15       True\n",
      "16      False\n",
      "17      False\n",
      "18      False\n",
      "19      False\n",
      "20       True\n",
      "21      False\n",
      "22      False\n",
      "23      False\n",
      "24      False\n",
      "25      False\n",
      "26      False\n",
      "27      False\n",
      "28      False\n",
      "29      False\n",
      "        ...  \n",
      "4116    False\n",
      "4117    False\n",
      "4118    False\n",
      "4119    False\n",
      "4120    False\n",
      "4121    False\n",
      "4122    False\n",
      "4123    False\n",
      "4124    False\n",
      "4125    False\n",
      "4126    False\n",
      "4127    False\n",
      "4128    False\n",
      "4129    False\n",
      "4130    False\n",
      "4131    False\n",
      "4132    False\n",
      "4133    False\n",
      "4134    False\n",
      "4135    False\n",
      "4136    False\n",
      "4137    False\n",
      "4138    False\n",
      "4139    False\n",
      "4140    False\n",
      "4141    False\n",
      "4142    False\n",
      "4143    False\n",
      "4144    False\n",
      "4145     True\n",
      "Name: label, Length: 4146, dtype: bool\n",
      "CPU times: user 30.5 s, sys: 20 ms, total: 30.5 s\n",
      "Wall time: 30.4 s\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "write() argument must be str, not dict",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-8ad4a336a3f5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     60\u001b[0m         \u001b[0mclf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGridSearchCV\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuned_parameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m         \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_line_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'time'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'clf.fit(X_train, Y_train)'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 62\u001b[0;31m         \u001b[0mfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_params_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     63\u001b[0m         \u001b[0mfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'\\n'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0mmeans\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcv_results_\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'mean_test_score'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: write() argument must be str, not dict"
     ]
    }
   ],
   "source": [
    "#construction of the lists\n",
    "estimators_list = [SVC(),KNeighborsClassifier(), LogisticRegression(), RandomForestClassifier()]\n",
    "tuned_parameters_list = [[{'kernel': ['rbf'], 'gamma': [1e-3, 1e-4], 'C': [1, 10, 100, 1000]}],\n",
    "                         [{'n_neighbors': [i for i in range(1,30)]}], \n",
    "                         [{'C': [1,10,100,1000], 'tol': [1e-5,1e-4,1e-3]}], \n",
    "                         [{'n_estimators': [10, 50, 100, 150, 200]}]]\n",
    "norm_list = [Normalizer(), StandardScaler(), MinMaxScaler()]\n",
    "names_list = [\"SVM\", \"KNN\", \"LR\", \"RF\"]\n",
    "transforms_list = [\"norm\",\"scale\",\"minmax\"]\n",
    "\n",
    "\n",
    "#breaking the data\n",
    "labels = features.label\n",
    "\n",
    "#normalization of the data\n",
    "tnfeatures = norm_list[0].transform(tfeatures.iloc[:-1,:])\n",
    "nfeatures = tnfeatures.T\n",
    "pfeatures = pd.concat([pd.DataFrame(data=nfeatures), labels], axis=1)\n",
    "print(pfeatures.iloc[:, -1])\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(pfeatures.iloc[:, :-1], pfeatures['label'], test_size=0.5, random_state=0)\n",
    "file = open(\"../reports/parameter_tuning_\"+transforms_list[0], 'w')\n",
    "\n",
    "for estimator, tuned_parameters, name in zip(estimators_list, tuned_parameters_list, names_list):\n",
    "    file.write(30*\"**\"+\"\\n\")\n",
    "    file.write('Grid Search for '+ name +'\\n')\n",
    "    clf = GridSearchCV(estimator, tuned_parameters, cv=10)\n",
    "    %time clf.fit(X_train, Y_train)\n",
    "    file.write(str(clf.best_params_))\n",
    "    file.write('\\n')\n",
    "    means = clf.cv_results_['mean_test_score']\n",
    "    stds = clf.cv_results_['std_test_score']\n",
    "    for mean, std, params in zip(means, stds, clf.cv_results_['params']):\n",
    "        file.write(\"%0.3f (+/-%0.03f) for %r\\n\"% (mean, std * 2, params))\n",
    "    file.write('\\n')\n",
    "    file.write('\\n')\n",
    "    y_true, y_pred = Y_test, clf.predict(X_test)\n",
    "    file.write(classification_report(y_true, y_pred))\n",
    "    file.write('\\n')\n",
    "    file.write('\\n')\n",
    "    file.write('\\n')\n",
    "file.close()\n",
    "\n",
    "#scaling of the data\n",
    "for norm, trans in zip(norm_list[1:], transforms_list[1:]):\n",
    "    print()\n",
    "    print()\n",
    "    print()\n",
    "    nfeatures = norm.fit_transform(features.iloc[:, :-1])\n",
    "    ###############################################################\n",
    "    pfeatures = pd.concat([pd.DataFrame(data=nfeatures), labels], axis=1)\n",
    "    print(pfeatures.iloc[:, -1])\n",
    "    ###############################################################\n",
    "    X_train, X_test, Y_train, Y_test = train_test_split(pfeatures.iloc[:, :-1], pfeatures['label'], test_size=0.5, random_state=0)\n",
    "    file = open(\"../reports/parameter_tuning_\"+trans, 'w')\n",
    "\n",
    "    for estimator, tuned_parameters, name in zip(estimators_list, tuned_parameters_list, names_list):\n",
    "        file.write(30*\"**\"+\"\\n\")\n",
    "        file.write('Grid Search for '+ name +'\\n')\n",
    "        clf = GridSearchCV(estimator, tuned_parameters, cv=10)\n",
    "        %time clf.fit(X_train, Y_train)\n",
    "        file.write((clf.best_params_))\n",
    "        file.write('\\n')\n",
    "        means = clf.cv_results_['mean_test_score']\n",
    "        stds = clf.cv_results_['std_test_score']\n",
    "        for mean, std, params in zip(means, stds, clf.cv_results_['params']):\n",
    "            file.write(\"%0.3f (+/-%0.03f) for %r\\n\"% (mean, std * 2, params))\n",
    "        file.write('\\n')\n",
    "        file.write('\\n')\n",
    "        y_true, y_pred = Y_test, clf.predict(X_test)\n",
    "        file.write(classification_report(y_true, y_pred))\n",
    "        file.write('\\n')\n",
    "        file.write('\\n')\n",
    "        file.write('\\n')\n",
    "    file.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimators_list = [SVC(),KNeighborsClassifier(), LogisticRegression(), RandomForestClassifier()]\n",
    "tuned_parameters_list = [[{'kernel': ['rbf'], 'gamma': [1e-3, 1e-4], 'C': [1, 10, 100, 1000]}],\n",
    "                         [{'n_neighbors': [i for i in range(1,30)]}], \n",
    "                         [{'C': [1,10,100,1000], 'tol': [1e-5,1e-4,1e-3]}], \n",
    "                         [{'n_estimators': [10, 50, 100, 150, 200]}]]\n",
    "norm_list = [Normalizer(), StandardScaler(), MinMaxScaler()]\n",
    "names_list = [\"SVM\", \"KNN\", \"LR\", \"RF\"]\n",
    "transforms_list = [\"norm\",\"scale\",\"minmax\"]\n",
    "\n",
    "tnfeatures = norm_list[0].transform(tfeatures)\n",
    "nfeatures = tnfeatures.T\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(nfeatures[:,:-1], nfeatures[:, -1], test_size=0.5, random_state=0)\n",
    "for estimator, tuned_parameters, name in zip(estimators_list, tuned_parameters_list, names_list):\n",
    "    print(estimator)\n",
    "    print(tuned_parameters)\n",
    "    print(name)\n",
    "    print()\n",
    "    print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
