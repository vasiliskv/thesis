{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import Normalizer, MinMaxScaler, StandardScaler\n",
    "from sklearn.svm import SVC \n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# use seaborn plotting defaults\n",
    "import seaborn as sns; sns.set()\n",
    "\n",
    "\n",
    "features = pd.read_csv(\"../data/new_labeled_features.csv\",index_col=0)\n",
    "tfeatures = features.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(features.iloc[:,:-1], features.label, test_size=0.5, random_state=0)\n",
    "\n",
    "\n",
    "print('Grid Search for SVM')\n",
    "tuned_parameters = [{'kernel': ['rbf'], 'gamma': [1e-3, 1e-4], 'C': [1, 10, 100, 1000]}]\n",
    "clf = GridSearchCV(SVC(), tuned_parameters, cv=10)\n",
    "%time clf.fit(X_train, Y_train)\n",
    "#print(clf.best_params_)\n",
    "print()\n",
    "means = clf.cv_results_['mean_test_score']\n",
    "stds = clf.cv_results_['std_test_score']\n",
    "for mean, std, params in zip(means, stds, clf.cv_results_['params']):\n",
    "    print(\"%0.3f (+/-%0.03f) for %r\"% (mean, std * 2, params))\n",
    "print()\n",
    "print()\n",
    "y_true, y_pred = Y_test, clf.predict(X_test)\n",
    "print(classification_report(y_true, y_pred))\n",
    "\n",
    "\n",
    "print()\n",
    "print()\n",
    "print('Grid Search for kNN')\n",
    "tuned_parameters = [{'n_neighbors': [i for i in range(1,30)]}]\n",
    "clf = GridSearchCV(KNeighborsClassifier(), tuned_parameters, cv=10)\n",
    "%time clf.fit(X_train, Y_train)\n",
    "#print(clf.best_params_)\n",
    "print()\n",
    "means = clf.cv_results_['mean_test_score']\n",
    "stds = clf.cv_results_['std_test_score']\n",
    "for mean, std, params in zip(means, stds, clf.cv_results_['params']):\n",
    "    print(\"%0.3f (+/-%0.03f) for %r\"% (mean, std * 2, params))\n",
    "print()\n",
    "print()\n",
    "y_true, y_pred = Y_test, clf.predict(X_test)\n",
    "print(classification_report(y_true, y_pred))\n",
    "\n",
    "\n",
    "print()\n",
    "print()\n",
    "print('Grid Search for logistic regression')\n",
    "tuned_parameters = [{'C': [1,10,100,1000], 'tol': [1e-5,1e-4,1e-3]}]\n",
    "clf = GridSearchCV(LogisticRegression(), tuned_parameters, cv=10)\n",
    "%time clf.fit(X_train, Y_train)\n",
    "#print(clf.best_params_)\n",
    "print()\n",
    "means = clf.cv_results_['mean_test_score']\n",
    "stds = clf.cv_results_['std_test_score']\n",
    "for mean, std, params in zip(means, stds, clf.cv_results_['params']):\n",
    "    print(\"%0.3f (+/-%0.03f) for %r\"% (mean, std * 2, params))\n",
    "print()\n",
    "print()\n",
    "y_true, y_pred = Y_test, clf.predict(X_test)\n",
    "print(classification_report(y_true, y_pred))\n",
    "\n",
    "print()\n",
    "print()\n",
    "print('Grid Search for random forest')\n",
    "tuned_parameters = [{'n_estimators': [10, 50, 100, 150, 200]}]\n",
    "clf = GridSearchCV(RandomForestClassifier(), tuned_parameters, cv=10)\n",
    "%time clf.fit(X_train, Y_train)\n",
    "#print(clf.best_params_)\n",
    "print()\n",
    "means = clf.cv_results_['mean_test_score']\n",
    "stds = clf.cv_results_['std_test_score']\n",
    "for mean, std, params in zip(means, stds, clf.cv_results_['params']):\n",
    "    print(\"%0.3f (+/-%0.03f) for %r\"% (mean, std * 2, params))\n",
    "print()\n",
    "print()\n",
    "y_true, y_pred = Y_test, clf.predict(X_test)\n",
    "print(classification_report(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open(\"../reports/parameter_tuning\", 'a')\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(features.iloc[:,:-1], features.label, test_size=0.5, random_state=0)\n",
    "\n",
    "\n",
    "file.write('Grid Search for SVM\\n')\n",
    "tuned_parameters = [{'kernel': ['rbf'], 'gamma': [1e-3, 1e-4], 'C': [1, 10, 100, 1000]}]\n",
    "clf = GridSearchCV(SVC(), tuned_parameters, cv=10)\n",
    "%time clf.fit(X_train, Y_train)\n",
    "#print(clf.best_params_)\n",
    "file.write('\\n')\n",
    "means = clf.cv_results_['mean_test_score']\n",
    "stds = clf.cv_results_['std_test_score']\n",
    "for mean, std, params in zip(means, stds, clf.cv_results_['params']):\n",
    "    file.write(\"%0.3f (+/-%0.03f) for %r\\n\"% (mean, std * 2, params))\n",
    "file.write('\\n')\n",
    "file.write('\\n')\n",
    "y_true, y_pred = Y_test, clf.predict(X_test)\n",
    "file.write(classification_report(y_true, y_pred))\n",
    "\n",
    "file.write('\\n')\n",
    "file.write('\\n')\n",
    "file.write('\\n')\n",
    "file.write('Grid Search for kNN\\n')\n",
    "tuned_parameters = [{'n_neighbors': [i for i in range(1,30)]}]\n",
    "clf = GridSearchCV(KNeighborsClassifier(), tuned_parameters, cv=10)\n",
    "%time clf.fit(X_train, Y_train)\n",
    "#print(clf.best_params_)\n",
    "file.write('\\n')\n",
    "means = clf.cv_results_['mean_test_score']\n",
    "stds = clf.cv_results_['std_test_score']\n",
    "for mean, std, params in zip(means, stds, clf.cv_results_['params']):\n",
    "    file.write(\"%0.3f (+/-%0.03f) for %r\\n\"% (mean, std * 2, params))\n",
    "file.write('\\n')\n",
    "file.write('\\n')\n",
    "y_true, y_pred = Y_test, clf.predict(X_test)\n",
    "file.write(classification_report(y_true, y_pred))\n",
    "\n",
    "file.write('\\n')\n",
    "file.write('\\n')\n",
    "file.write('\\n')\n",
    "file.write('Grid Search for logistic regression\\n')\n",
    "tuned_parameters = [{'C': [1,10,100,1000], 'tol': [1e-5,1e-4,1e-3]}]\n",
    "clf = GridSearchCV(LogisticRegression(), tuned_parameters, cv=10)\n",
    "%time clf.fit(X_train, Y_train)\n",
    "#print(clf.best_params_)\n",
    "file.write('\\n')\n",
    "means = clf.cv_results_['mean_test_score']\n",
    "stds = clf.cv_results_['std_test_score']\n",
    "for mean, std, params in zip(means, stds, clf.cv_results_['params']):\n",
    "    file.write(\"%0.3f (+/-%0.03f) for %r\\n\"% (mean, std * 2, params))\n",
    "file.write('\\n')\n",
    "file.write('\\n')\n",
    "y_true, y_pred = Y_test, clf.predict(X_test)\n",
    "file.writelines(classification_report(y_true, y_pred))\n",
    "\n",
    "file.write('\\n')\n",
    "file.write('\\n')\n",
    "file.write('\\n')\n",
    "file.write('Grid Search for random forest\\n')\n",
    "tuned_parameters = [{'n_estimators': [10, 50, 100, 150, 200]}]\n",
    "clf = GridSearchCV(RandomForestClassifier(), tuned_parameters, cv=10)\n",
    "%time clf.fit(X_train, Y_train)\n",
    "#print(clf.best_params_)\n",
    "file.write('\\n')\n",
    "means = clf.cv_results_['mean_test_score']\n",
    "stds = clf.cv_results_['std_test_score']\n",
    "for mean, std, params in zip(means, stds, clf.cv_results_['params']):\n",
    "    file.write(\"%0.3f (+/-%0.03f) for %r\\n\"% (mean, std * 2, params))\n",
    "file.write('\\n')\n",
    "file.write('\\n')\n",
    "y_true, y_pred = Y_test, clf.predict(X_test)\n",
    "file.writelines(classification_report(y_true, y_pred))\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 37.7 s, sys: 24 ms, total: 37.8 s\n",
      "Wall time: 37.8 s\n",
      "CPU times: user 1min 19s, sys: 956 ms, total: 1min 20s\n",
      "Wall time: 45 s\n",
      "CPU times: user 40.2 s, sys: 712 ms, total: 40.9 s\n",
      "Wall time: 22.3 s\n",
      "CPU times: user 58.1 s, sys: 16 ms, total: 58.2 s\n",
      "Wall time: 58 s\n"
     ]
    }
   ],
   "source": [
    "file = open(\"../reports/parameter_tuning\", 'w')\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(features.iloc[:,:-1], features.label, test_size=0.5, random_state=0)\n",
    "\n",
    "estimators_list = [SVC(),KNeighborsClassifier(), LogisticRegression(), RandomForestClassifier()]\n",
    "tuned_parameters_list = [[{'kernel': ['rbf'], 'gamma': [1e-3, 1e-4], 'C': [1, 10, 100, 1000]}],\n",
    "                         [{'n_neighbors': [i for i in range(1,30)]}], \n",
    "                         [{'C': [1,10,100,1000], 'tol': [1e-5,1e-4,1e-3]}], \n",
    "                         [{'n_estimators': [10, 50, 100, 150, 200]}]]\n",
    "names_list = [\"SVM\", \"KNN\", \"LR\", \"RF\"]\n",
    "\n",
    "for estimator, tuned_parameters, name in zip(estimators_list, tuned_parameters_list, names_list):\n",
    "    file.write(30*\"**\"+\"\\n\")\n",
    "    file.write('Grid Search for '+ name +'\\n')\n",
    "    clf = GridSearchCV(estimator, tuned_parameters, cv=10)\n",
    "    %time clf.fit(X_train, Y_train)\n",
    "    file.write(str(clf.best_params_))\n",
    "    file.write('\\n')\n",
    "    means = clf.cv_results_['mean_test_score']\n",
    "    stds = clf.cv_results_['std_test_score']\n",
    "    for mean, std, params in zip(means, stds, clf.cv_results_['params']):\n",
    "        file.write(\"%0.3f (+/-%0.03f) for %r\\n\"% (mean, std * 2, params))\n",
    "    file.write('\\n')\n",
    "    file.write('\\n')\n",
    "    y_true, y_pred = Y_test, clf.predict(X_test)\n",
    "    file.write(classification_report(y_true, y_pred))\n",
    "    file.write('\\n')\n",
    "    file.write('\\n')\n",
    "    file.write('\\n')\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0        True\n",
      "1        True\n",
      "2        True\n",
      "3        True\n",
      "4       False\n",
      "5        True\n",
      "6       False\n",
      "7       False\n",
      "8       False\n",
      "9       False\n",
      "10      False\n",
      "11      False\n",
      "12      False\n",
      "13      False\n",
      "14       True\n",
      "15       True\n",
      "16      False\n",
      "17      False\n",
      "18      False\n",
      "19      False\n",
      "20       True\n",
      "21      False\n",
      "22      False\n",
      "23      False\n",
      "24      False\n",
      "25      False\n",
      "26      False\n",
      "27      False\n",
      "28      False\n",
      "29      False\n",
      "        ...  \n",
      "4116    False\n",
      "4117    False\n",
      "4118    False\n",
      "4119    False\n",
      "4120    False\n",
      "4121    False\n",
      "4122    False\n",
      "4123    False\n",
      "4124    False\n",
      "4125    False\n",
      "4126    False\n",
      "4127    False\n",
      "4128    False\n",
      "4129    False\n",
      "4130    False\n",
      "4131    False\n",
      "4132    False\n",
      "4133    False\n",
      "4134    False\n",
      "4135    False\n",
      "4136    False\n",
      "4137    False\n",
      "4138    False\n",
      "4139    False\n",
      "4140    False\n",
      "4141    False\n",
      "4142    False\n",
      "4143    False\n",
      "4144    False\n",
      "4145     True\n",
      "Name: label, Length: 4146, dtype: bool\n",
      "CPU times: user 31.3 s, sys: 4 ms, total: 31.3 s\n",
      "Wall time: 31.1 s\n",
      "CPU times: user 2min 34s, sys: 1.1 s, total: 2min 35s\n",
      "Wall time: 1min 53s\n",
      "CPU times: user 14.4 s, sys: 288 ms, total: 14.7 s\n",
      "Wall time: 7.37 s\n",
      "CPU times: user 1min 1s, sys: 0 ns, total: 1min 1s\n",
      "Wall time: 1min\n",
      "\n",
      "\n",
      "\n",
      "0        True\n",
      "1        True\n",
      "2        True\n",
      "3        True\n",
      "4       False\n",
      "5        True\n",
      "6       False\n",
      "7       False\n",
      "8       False\n",
      "9       False\n",
      "10      False\n",
      "11      False\n",
      "12      False\n",
      "13      False\n",
      "14       True\n",
      "15       True\n",
      "16      False\n",
      "17      False\n",
      "18      False\n",
      "19      False\n",
      "20       True\n",
      "21      False\n",
      "22      False\n",
      "23      False\n",
      "24      False\n",
      "25      False\n",
      "26      False\n",
      "27      False\n",
      "28      False\n",
      "29      False\n",
      "        ...  \n",
      "4116    False\n",
      "4117    False\n",
      "4118    False\n",
      "4119    False\n",
      "4120    False\n",
      "4121    False\n",
      "4122    False\n",
      "4123    False\n",
      "4124    False\n",
      "4125    False\n",
      "4126    False\n",
      "4127    False\n",
      "4128    False\n",
      "4129    False\n",
      "4130    False\n",
      "4131    False\n",
      "4132    False\n",
      "4133    False\n",
      "4134    False\n",
      "4135    False\n",
      "4136    False\n",
      "4137    False\n",
      "4138    False\n",
      "4139    False\n",
      "4140    False\n",
      "4141    False\n",
      "4142    False\n",
      "4143    False\n",
      "4144    False\n",
      "4145     True\n",
      "Name: label, Length: 4146, dtype: bool\n",
      "CPU times: user 30.8 s, sys: 4 ms, total: 30.8 s\n",
      "Wall time: 30.6 s\n",
      "CPU times: user 2min 32s, sys: 1.16 s, total: 2min 34s\n",
      "Wall time: 1min 52s\n",
      "CPU times: user 1min 40s, sys: 960 ms, total: 1min 41s\n",
      "Wall time: 1min 18s\n",
      "CPU times: user 1min 2s, sys: 0 ns, total: 1min 2s\n",
      "Wall time: 1min 2s\n",
      "\n",
      "\n",
      "\n",
      "0        True\n",
      "1        True\n",
      "2        True\n",
      "3        True\n",
      "4       False\n",
      "5        True\n",
      "6       False\n",
      "7       False\n",
      "8       False\n",
      "9       False\n",
      "10      False\n",
      "11      False\n",
      "12      False\n",
      "13      False\n",
      "14       True\n",
      "15       True\n",
      "16      False\n",
      "17      False\n",
      "18      False\n",
      "19      False\n",
      "20       True\n",
      "21      False\n",
      "22      False\n",
      "23      False\n",
      "24      False\n",
      "25      False\n",
      "26      False\n",
      "27      False\n",
      "28      False\n",
      "29      False\n",
      "        ...  \n",
      "4116    False\n",
      "4117    False\n",
      "4118    False\n",
      "4119    False\n",
      "4120    False\n",
      "4121    False\n",
      "4122    False\n",
      "4123    False\n",
      "4124    False\n",
      "4125    False\n",
      "4126    False\n",
      "4127    False\n",
      "4128    False\n",
      "4129    False\n",
      "4130    False\n",
      "4131    False\n",
      "4132    False\n",
      "4133    False\n",
      "4134    False\n",
      "4135    False\n",
      "4136    False\n",
      "4137    False\n",
      "4138    False\n",
      "4139    False\n",
      "4140    False\n",
      "4141    False\n",
      "4142    False\n",
      "4143    False\n",
      "4144    False\n",
      "4145     True\n",
      "Name: label, Length: 4146, dtype: bool\n",
      "CPU times: user 32.1 s, sys: 8 ms, total: 32.1 s\n",
      "Wall time: 31.9 s\n",
      "CPU times: user 1min 44s, sys: 1.16 s, total: 1min 45s\n",
      "Wall time: 1min 3s\n",
      "CPU times: user 25.3 s, sys: 532 ms, total: 25.8 s\n",
      "Wall time: 13.4 s\n",
      "CPU times: user 1min, sys: 8 ms, total: 1min\n",
      "Wall time: 1min\n"
     ]
    }
   ],
   "source": [
    "#construction of the lists\n",
    "estimators_list = [SVC(),KNeighborsClassifier(), LogisticRegression(), RandomForestClassifier()]\n",
    "tuned_parameters_list = [[{'kernel': ['rbf'], 'gamma': [1e-3, 1e-4], 'C': [1, 10, 100, 1000]}],\n",
    "                         [{'n_neighbors': [i for i in range(1,30)]}], \n",
    "                         [{'C': [1,10,100,1000], 'tol': [1e-5,1e-4,1e-3]}], \n",
    "                         [{'n_estimators': [10, 50, 100, 150, 200]}]]\n",
    "norm_list = [Normalizer(), StandardScaler(), MinMaxScaler()]\n",
    "names_list = [\"SVM\", \"KNN\", \"LR\", \"RF\"]\n",
    "transforms_list = [\"norm\",\"scale\",\"minmax\"]\n",
    "\n",
    "\n",
    "#breaking the data\n",
    "labels = features.label\n",
    "\n",
    "#normalization of the data\n",
    "tnfeatures = norm_list[0].transform(tfeatures.iloc[:-1,:])\n",
    "nfeatures = tnfeatures.T\n",
    "pfeatures = pd.concat([pd.DataFrame(data=nfeatures), labels], axis=1)\n",
    "print(pfeatures.iloc[:, -1])\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(pfeatures.iloc[:, :-1], pfeatures['label'], test_size=0.5, random_state=0)\n",
    "file = open(\"../reports/parameter_tuning_\"+transforms_list[0], 'w')\n",
    "\n",
    "for estimator, tuned_parameters, name in zip(estimators_list, tuned_parameters_list, names_list):\n",
    "    file.write(30*\"**\"+\"\\n\")\n",
    "    file.write('Grid Search for '+ name +'\\n')\n",
    "    clf = GridSearchCV(estimator, tuned_parameters, cv=10)\n",
    "    %time clf.fit(X_train, Y_train)\n",
    "    file.write(str(clf.best_params_))\n",
    "    file.write('\\n')\n",
    "    means = clf.cv_results_['mean_test_score']\n",
    "    stds = clf.cv_results_['std_test_score']\n",
    "    for mean, std, params in zip(means, stds, clf.cv_results_['params']):\n",
    "        file.write(\"%0.3f (+/-%0.03f) for %r\\n\"% (mean, std * 2, params))\n",
    "    file.write('\\n')\n",
    "    file.write('\\n')\n",
    "    y_true, y_pred = Y_test, clf.predict(X_test)\n",
    "    file.write(classification_report(y_true, y_pred))\n",
    "    file.write('\\n')\n",
    "    file.write('\\n')\n",
    "    file.write('\\n')\n",
    "file.close()\n",
    "\n",
    "#scaling of the data\n",
    "for norm, trans in zip(norm_list[1:], transforms_list[1:]):\n",
    "    print()\n",
    "    print()\n",
    "    print()\n",
    "    nfeatures = norm.fit_transform(features.iloc[:, :-1])\n",
    "    ###############################################################\n",
    "    pfeatures = pd.concat([pd.DataFrame(data=nfeatures), labels], axis=1)\n",
    "    print(pfeatures.iloc[:, -1])\n",
    "    ###############################################################\n",
    "    X_train, X_test, Y_train, Y_test = train_test_split(pfeatures.iloc[:, :-1], pfeatures['label'], test_size=0.5, random_state=0)\n",
    "    file = open(\"../reports/parameter_tuning_\"+trans, 'w')\n",
    "\n",
    "    for estimator, tuned_parameters, name in zip(estimators_list, tuned_parameters_list, names_list):\n",
    "        file.write(30*\"**\"+\"\\n\")\n",
    "        file.write('Grid Search for '+ name +'\\n')\n",
    "        clf = GridSearchCV(estimator, tuned_parameters, cv=10)\n",
    "        %time clf.fit(X_train, Y_train)\n",
    "        file.write(str(clf.best_params_))\n",
    "        file.write('\\n')\n",
    "        means = clf.cv_results_['mean_test_score']\n",
    "        stds = clf.cv_results_['std_test_score']\n",
    "        for mean, std, params in zip(means, stds, clf.cv_results_['params']):\n",
    "            file.write(\"%0.3f (+/-%0.03f) for %r\\n\"% (mean, std * 2, params))\n",
    "        file.write('\\n')\n",
    "        file.write('\\n')\n",
    "        y_true, y_pred = Y_test, clf.predict(X_test)\n",
    "        file.write(classification_report(y_true, y_pred))\n",
    "        file.write('\\n')\n",
    "        file.write('\\n')\n",
    "        file.write('\\n')\n",
    "    file.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimators_list = [SVC(),KNeighborsClassifier(), LogisticRegression(), RandomForestClassifier()]\n",
    "tuned_parameters_list = [[{'kernel': ['rbf'], 'gamma': [1e-3, 1e-4], 'C': [1, 10, 100, 1000]}],\n",
    "                         [{'n_neighbors': [i for i in range(1,30)]}], \n",
    "                         [{'C': [1,10,100,1000], 'tol': [1e-5,1e-4,1e-3]}], \n",
    "                         [{'n_estimators': [10, 50, 100, 150, 200]}]]\n",
    "norm_list = [Normalizer(), StandardScaler(), MinMaxScaler()]\n",
    "names_list = [\"SVM\", \"KNN\", \"LR\", \"RF\"]\n",
    "transforms_list = [\"norm\",\"scale\",\"minmax\"]\n",
    "\n",
    "tnfeatures = norm_list[0].transform(tfeatures)\n",
    "nfeatures = tnfeatures.T\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(nfeatures[:,:-1], nfeatures[:, -1], test_size=0.5, random_state=0)\n",
    "for estimator, tuned_parameters, name in zip(estimators_list, tuned_parameters_list, names_list):\n",
    "    print(estimator)\n",
    "    print(tuned_parameters)\n",
    "    print(name)\n",
    "    print()\n",
    "    print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
